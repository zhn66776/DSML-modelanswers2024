{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fe03486",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "Here we will use simply the dataset of porosity vs NGR and %Carbonate that we used before. This is a simplified version of the dataset, and it contains no labels (only numerical values are included). The data file is saved in 'Datasets/core_data.csv'.\n",
    "\n",
    "You are now an expert at data preparation, so do the following for the above dataset:\n",
    "\n",
    "* Remove duplicates\n",
    "* Separate the target (`porosity %` - call it `y`) from the features (call them `X`)\n",
    "* Split the dataset into 70% training, 30% testing. To ensure we get the same results use a `random_state` value of 42.\n",
    "* Using a pipeline, impute missing values using a `SimpleImputer` class with a `mean` strategy and a `MinMaxScaler`\n",
    "\n",
    "You should know how to do all of the above except for splitting the target and the features. You can use the brief code block below for inspiration:\n",
    "\n",
    "```python\n",
    "# Create features (drop the target columns)\n",
    "X = data.drop(columns = 'porosity %')\n",
    "\n",
    "# Create target\n",
    "y = data['porosity %'] \n",
    "\n",
    "# Split the data using train/test split. Note that when you provide two dataframes (X and y), it will split them up \n",
    "# in the order shown\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, random_state = 42)\n",
    "```\n",
    "\n",
    "After following your data preparation pipeline, you should end up with 4 dataframes (`X_train`, `X_test`, `y_train`, `y_test`), two of them scaled (`X_train`, `X_test`).\n",
    "\n",
    "**Tip 1:** If you get stuck, you can refer to last week's exercise (this is essentially the same workflow). That said, I do recommend that you try and go as far as you can on your own: it is important to practice to be able to do it without the need to refer to previous code...\n",
    "\n",
    "**Tip 2:** The `sklearn` `Pipeline` class will return a Numpy Array, not a Pandas Dataframe. For many applications, this is ok as you no longer need to explore your dataset once it has been prepared; you simply need to send it to another `sklearn` object, which accept numpy arrays without complaint. But in our case, we will want to convenience of calling specific columns later. So make sure that both `X_train` and `X_test` are Dataframes (you can refer to the documentation to see how to turn Numpy arrays directly into DataFrames). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af92ff7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Depth CSF-A (m)</th>\n",
       "      <th>NGR total counts (cps)</th>\n",
       "      <th>Reflectance L*</th>\n",
       "      <th>Reflectance a*</th>\n",
       "      <th>Reflectance b*</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3523.000000</td>\n",
       "      <td>3523.000000</td>\n",
       "      <td>3523.000000</td>\n",
       "      <td>3523.000000</td>\n",
       "      <td>3523.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.157809</td>\n",
       "      <td>0.308861</td>\n",
       "      <td>0.461757</td>\n",
       "      <td>0.295851</td>\n",
       "      <td>0.389865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.194801</td>\n",
       "      <td>0.166321</td>\n",
       "      <td>0.130924</td>\n",
       "      <td>0.086793</td>\n",
       "      <td>0.089343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.037054</td>\n",
       "      <td>0.198967</td>\n",
       "      <td>0.373418</td>\n",
       "      <td>0.242105</td>\n",
       "      <td>0.321976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.088918</td>\n",
       "      <td>0.275715</td>\n",
       "      <td>0.449367</td>\n",
       "      <td>0.270175</td>\n",
       "      <td>0.376491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.196690</td>\n",
       "      <td>0.398285</td>\n",
       "      <td>0.534177</td>\n",
       "      <td>0.329825</td>\n",
       "      <td>0.454855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Depth CSF-A (m)  NGR total counts (cps)  Reflectance L*  \\\n",
       "count      3523.000000             3523.000000     3523.000000   \n",
       "mean          0.157809                0.308861        0.461757   \n",
       "std           0.194801                0.166321        0.130924   \n",
       "min           0.000000                0.000000        0.000000   \n",
       "25%           0.037054                0.198967        0.373418   \n",
       "50%           0.088918                0.275715        0.449367   \n",
       "75%           0.196690                0.398285        0.534177   \n",
       "max           1.000000                1.000000        1.000000   \n",
       "\n",
       "       Reflectance a*  Reflectance b*  \n",
       "count     3523.000000     3523.000000  \n",
       "mean         0.295851        0.389865  \n",
       "std          0.086793        0.089343  \n",
       "min          0.000000        0.000000  \n",
       "25%          0.242105        0.321976  \n",
       "50%          0.270175        0.376491  \n",
       "75%          0.329825        0.454855  \n",
       "max          1.000000        1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# Import everything\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "data = pd.read_csv('Data/core_data_trunc.csv')\n",
    "\n",
    "data.drop_duplicates(inplace = True)\n",
    "\n",
    "# Split the data into features (X) and the target variable (y)\n",
    "X = data.drop(columns = 'Porosity (vol%)')\n",
    "y = data['Porosity (vol%)']\n",
    "\n",
    "# Split into training and testing sets\n",
    "# Each sample in X_train has a corresponding y_train value\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "# define function that removes negative NGR\n",
    "def remove_negative_values(df):\n",
    "    df = df[df['NGR total counts (cps)'] > 0]    \n",
    "    return df\n",
    "\n",
    "X_train = remove_negative_values(X_train)\n",
    "X_test = remove_negative_values(X_test)\n",
    "\n",
    "# Create a pipeline that does our preprocessing for us\n",
    "pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer()),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the X_train object, then transform the data\n",
    "# Note that we don't need to do the whole numeric column thing from Lecture 4 because\n",
    "# our data no longer contains any non-numeric data\n",
    "X_train_prep = pipe.fit_transform(X_train)\n",
    "X_test_prep = pipe.transform(X_test)\n",
    "\n",
    "# Prove to yourself that all values have been scaled from 0-1\n",
    "pd.DataFrame(X_train_prep, columns = X_train.columns).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201aa4d4",
   "metadata": {},
   "source": [
    "# Exercise 2: Incorporating ML models in pipelines\n",
    "\n",
    "By now you should be somewhat familiar with pipelines since you've been using them to prepare your data since the last lecture. But the real power of pipelines is that they allow you to pair data preparation and model training into a single pipeline. All you have to do is simply add a predictor (i.e., a model) at your last step in our pipeline. Then, to assess our model, all we need to do is:\n",
    "\n",
    "* `fit` your pipeline on `X_train`\n",
    "* use your pipeline to `predict` the `y_test`\n",
    "\n",
    "Note that you no longer need to save the intermediate transformed `X_train` and `X_test` dataframe: the `transform` method is called under the hood by the pipeline for you.\n",
    "\n",
    "In the following cell, redo Exercise 1 but this time incorporate a `LinearRegression()` model into your pipeline, `fit` it, and create a `y_pred` prediction from your test set. Call your pipeline `ols_pipe` (for 'ordinary least square'): we will reuse it in the rest of this notebook.\n",
    "\n",
    "**Tip:** You will need to resplit the data as the current `X_train` and `X_test` are already scaled, but you can copy most of your code from Exercise 1 so this will be quick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3e276fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[57.47, 65.94, 64.71, 63.85, 55.76, 55.33, 52.05, 53.59],\n",
       "       [57.  , 75.6 , 73.8 , 62.2 , 56.2 , 27.6 , 56.2 , 49.  ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Repeat the preprocessing steps from Exercise 1\n",
    "data = pd.read_csv('Data/core_data_trunc.csv')\n",
    "\n",
    "data.drop_duplicates(inplace = True)\n",
    "\n",
    "X = data.drop(columns = 'Porosity (vol%)')\n",
    "y = data['Porosity (vol%)']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "def remove_negative_values(df):\n",
    "    df = df[df['NGR total counts (cps)'] > 0]    \n",
    "    return df\n",
    "\n",
    "X_train = remove_negative_values(X_train)\n",
    "X_test = remove_negative_values(X_test)\n",
    "\n",
    "# The only difference is that now we add the linear regression model at the end\n",
    "ols_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer()),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('linreg', LinearRegression())\n",
    "])\n",
    "\n",
    "# Remember that when using a pipeline, we are very specifically asking for an output from\n",
    "# the very last element in the pipeline\n",
    "\n",
    "# Thus, we first want to FIT our linear regression model to training set. To do this, we need\n",
    "# to give it the X and y data from the training set:\n",
    "ols_pipe.fit(X_train, y_train)\n",
    "\n",
    "# We can then used the FITTED model to predict y data for a given set of X data from the testing set\n",
    "y_pred = ols_pipe.predict(X_test)\n",
    "\n",
    "# You can do a crude comparison between the predicted (top) and the actual (bottom) data \n",
    "# Here i'm comparing the first 8 predicted/actual porosities...\n",
    "np.array([np.round(y_pred, 2), y_test])[:, :8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59dbcbf",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "Following the example above, now calculate the MSE, RMSE, MAE, Max Error and R^2 for your model, and print the results neatly.\n",
    "\n",
    "**Tip:** You will need to check the `sklearn` documentation to be able to find the names of the different metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3f40a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 113.85\n",
      "RMSE = 10.67\n",
      "MAE = 8.17\n",
      "R2 = 0.59\n",
      "Max Error = 50.35\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, max_error, r2_score\n",
    "\n",
    "# All scoring takes in the actual and predicted values in that order\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "rsquared = r2_score(y_test, y_pred)\n",
    "\n",
    "max_error = max_error(y_test, y_pred)\n",
    "\n",
    "# I have rounded everything to 2 decimal points for clarity\n",
    "# The important thing to learn here is when to use which metric. \n",
    "# I personally really like using RMSE since that's the easiest metric to explain\n",
    "print('MSE =', np.round(mse, 2))\n",
    "print('RMSE =', np.round(rmse, 2))\n",
    "print('MAE =', np.round(mae, 2))\n",
    "print('R2 =', np.round(rsquared, 2))\n",
    "print('Max Error =', np.round(max_error, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49410fd",
   "metadata": {},
   "source": [
    "# Exercise 4\n",
    "\n",
    "Now that you know how to extract specific bits of a trained pipeline, do the following:\n",
    "\n",
    "1. Create a dataframe that contains 6 columns and 2 rows. The six columns will be the intercepts calculated by the machine learning algorithms: these are the coefficients given to each feature of the model. We will have two rows because we want to compare the values returned by the `LinearRegression` pipeline and the `SGDRegressor` pipeline. Make sure that you use the column names from the original X_train dataset for your coefficients; the coefficients returned by the `.coefs` attribute are in the same order as in the training data.\n",
    "2. Check whether the intercept and coefficients are similar between the two models: does the SGD approximation do a good job at capturing the coefficients identified by the OLS model?\n",
    "3. Based on the values of the coefficients, can you tell which of the 5 features we have used to predict porosity is the most important? Remember that because our data is scaled (i.e., all values are between 0 and 1) the coefficient is a direct indication of the relative importance of each feature. If you were to keep only 2 features to retrain a predictive model of porosity, which features would you keep?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9aec146e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Depth CSF-A (m)</th>\n",
       "      <th>NGR total counts (cps)</th>\n",
       "      <th>Reflectance L*</th>\n",
       "      <th>Reflectance a*</th>\n",
       "      <th>Reflectance b*</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ols</th>\n",
       "      <td>-64.091323</td>\n",
       "      <td>-34.633535</td>\n",
       "      <td>-13.216320</td>\n",
       "      <td>-12.008224</td>\n",
       "      <td>-2.911873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sgd</th>\n",
       "      <td>-64.094330</td>\n",
       "      <td>-34.175381</td>\n",
       "      <td>-13.046445</td>\n",
       "      <td>-10.858006</td>\n",
       "      <td>-2.445969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Depth CSF-A (m)  NGR total counts (cps)  Reflectance L*  Reflectance a*  \\\n",
       "ols       -64.091323              -34.633535      -13.216320      -12.008224   \n",
       "sgd       -64.094330              -34.175381      -13.046445      -10.858006   \n",
       "\n",
       "     Reflectance b*  \n",
       "ols       -2.911873  \n",
       "sgd       -2.445969  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression intercept: 85.19402041232287\n",
      "SGDRegressor intercept: [84.19691801]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate and train the pipeline object\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "sgd_reg = SGDRegressor(max_iter = 50, tol = 0, penalty = None, eta0 = 0.1, random_state = 42)\n",
    "\n",
    "# Following best practice, let's define a pipeline:\n",
    "\n",
    "sgd_pipe = Pipeline([('imputer', SimpleImputer()),\n",
    "                    ('scaler', MinMaxScaler()),\n",
    "                    ('regressor',sgd_reg)])\n",
    "\n",
    "sgd_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Extract the coefficients from the LinearRegression pipeline\n",
    "# and the SGD regressor pipeline\n",
    "\n",
    "ols_coefs = ols_pipe['linreg'].coef_\n",
    "sgd_coefs = sgd_pipe['regressor'].coef_\n",
    "\n",
    "# put them into a numpy array\n",
    "coef_arr = np.array([ols_coefs, sgd_coefs])\n",
    "\n",
    "# Create a dataframe from that numpy array\n",
    "# Give the dataframe the appropriate column and index names\n",
    "display(pd.DataFrame(coef_arr, columns = X_train.columns, index = ['ols', 'sgd']))\n",
    "\n",
    "print('LinearRegression intercept:', ols_pipe['linreg'].intercept_)\n",
    "print('SGDRegressor intercept:', sgd_pipe['regressor'].intercept_)\n",
    "\n",
    "# Since our data is scaled, the coefficient allows for a direct comparison between features\n",
    "# Thus, depth is twice as important as NGR counts, 5-6 times more important than Reflectance, etc.\n",
    "\n",
    "# For those of you who are interested in math, what's happening is:\n",
    "# (depth * -64.09) + (NGR * -34.6) + (Reflectance L * -13.2) + ... + 85.19 (intercept) = predicted_value\n",
    "\n",
    "# You can prove this to yourself below; both pieces of code will give you the same result:\n",
    "#     (X_test_prep[0,:] * ols_pipe['linreg'].coef_).sum() + ols_pipe['linreg'].intercept_\n",
    "#     ols_pipe.predict(X_test)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a1e43e",
   "metadata": {},
   "source": [
    "# Exercise 5\n",
    "\n",
    "Classification models (in our case, we'll be using the `LogisticRegression()` model in the `linear_model` module of `sklearn`) are trained exactly the same way as a regression model. Of course, the target variable is different: instead of a continuous value, the y_train and y_test values are now discrete classes.\n",
    "\n",
    "You'll be working with the same dataset in this exercise, as you did in the previous exercises, but you will first transform the variable '% porosity' into a class.\n",
    "\n",
    "Do the following:\n",
    "\n",
    "1. Open the file 'Datasets/core_data.csv' once again.\n",
    "2. Create an `X` variable containing all of the features, except porosity.\n",
    "3. Create a `y` variable where the value is 0 if the sample has <53% porosity, or 1 if it has >=53% porosity. There are several ways to do this, but I recommend using an anonymous function and the `.apply()` dataframe method (this is the simplest)\n",
    "4. Train-test split as before (70/30, random_state=42)\n",
    "5. Write a pipeline that includes an imputer (strategy=mean), a scaler (MinMax) and a LogisticRegression classifier. Fit your pipeline to the `X_train` and `y_train` data.\n",
    "6. Predict the class of your `X_test` and save it as `y_pred`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f7896f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, ..., 1, 1, 1],\n",
       "       [0, 1, 0, ..., 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Once again, the preprocessing steps are exactly the same\n",
    "# with the small exception that LogisticRegression is used for final object in the pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "data = pd.read_csv('Data/core_data_trunc.csv')\n",
    "data.drop_duplicates(inplace = True)\n",
    "\n",
    "# Repeat the standard preprocessing steps\n",
    "# However, we want to transform the porosity data from a numeric value to a categorical\n",
    "# The porosity data is now either 0 (low) or 1 (high).\n",
    "X = data.drop(columns = 'Porosity (vol%)')\n",
    "y = data['Porosity (vol%)'].apply(lambda x: np.where(x < 53, 0, 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, random_state=42)\n",
    "\n",
    "# Create a LogisticRegression pipeline\n",
    "pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer()),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Fit our pipeline\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Use our trained pipeline to predict the y values for a given X_test\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "np.array([y_pred, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d5695d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generates a NxN confusion matrix, where N is the number of classes being predicted\n",
    "# Output is a numpy array that we can visualize using a heatmap\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create a heatmap. fmt = 'g' prevents seaborn from using scientific notation on this plot\n",
    "sns.heatmap(cm, annot = True, cmap = 'coolwarm', fmt = 'g')\n",
    "\n",
    "plt.xlabel('Predicted Value', fontsize = 14, weight = 'bold')\n",
    "plt.ylabel('Actual Value', fontsize = 14, weight = 'bold');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9e64ed",
   "metadata": {},
   "source": [
    "## Exercise 6\n",
    "\n",
    "Congratulations! This is the last exercise of the day (unless you attempt the optional one). In this exercise, you will compute all of the metrics described above for your LogisticRegression model. This is similar to exercise 3, but this time for a classification task.\n",
    "\n",
    "**Tip:** Again, the hardest bit of this exercise is actually to find how the different metrics are named in `sklearn`. The rest you have done before - so consult the documentation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d24107d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.85\n",
      "Precision = 0.81\n",
      "Recall = 0.91\n",
      "F1 = 0.86\n"
     ]
    }
   ],
   "source": [
    "# Most of the information here can actually be gleaned from the confusion matrix, but its good to know \n",
    "# how to calculate the actual values from sklearn\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "accuracy=accuracy_score(y_test, y_pred)\n",
    "\n",
    "precision = precision_score(y_test,y_pred)\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print('Accuracy =', np.round(accuracy, 2))\n",
    "print('Precision =', np.round(precision, 2))\n",
    "print('Recall =', np.round(recall, 2))\n",
    "print('F1 =', np.round(f1, 2))\n",
    "\n",
    "# Don't worry if the numbers are very slightly different: these could be due to differences\n",
    "# in preprocessing, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28947fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
